{
    "cells": [
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Text Classification with Scikit-Learn\n",
                "\n",
                "The goal of this workshop is to explore text classification with scikit-learn, a widely used library.\n",
                "\n",
                "In this pre-work, you will see how to do text classification on a collection of text documents on different topics.\n",
                "\n",
                "We will:\n",
                "- Read in data\n",
                "- Extract feature vectors\n",
                "- Train a linear model to perform categorization\n",
                "- Find a good configuration of both the feature extraction components and the classifier\n",
                "\n",
                "These activities are adapted from the \"Working with Text Data\" scikit-learn tutorial (no longer available, but contained in [v1.4](https://scikit-learn.org/1.4/tutorial/text_analytics/working_with_text_data.html) of the documentation).\n",
                "\n",
                "**You are welcome to download and run this notebook somewhere else** (e.g., on your local computer). If you do, you will need to have [scikit-learn](https://scikit-learn.org/1.4/install.html#installation-instructions) installed.\n"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Loading the 20 newsgroups dataset\n",
                "\n",
                "We will be using a classic dataset called “Twenty Newsgroups”. Here is the official description, quoted from [the website](http://qwone.com/~jason/20Newsgroups/):\n",
                "\n",
                "\"The 20 Newsgroups data set is a collection of approximately 20,000 newsgroup documents, partitioned (nearly) evenly across 20 different newsgroups. To the best of our knowledge, it was originally collected by Ken Lang, probably for his paper “Newsweeder: Learning to filter netnews,” though he does not explicitly mention this collection. The 20 newsgroups collection has become a popular data set for experiments in text applications of machine learning techniques, such as text classification and text clustering.\"\n",
                "\n",
                "The code below uses scikit-learn's built-in dataset loader for 20 newsgroups. Alternatively, it is possible to download the dataset manually from the website and use the [sklearn.datasets.load_files](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_files.html) function by pointing it to the `20news-bydate-train sub-folder` of the uncompressed archive folder.\n",
                "\n",
                "In order to get faster execution times for this first example, we will work on a partial dataset with only 4 categories out of the 20 available in the dataset:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 63,
            "metadata": {},
            "outputs": [],
            "source": [
                "categories = ['comp.sys.mac.hardware', 'rec.sport.baseball',\n",
                "               'comp.graphics', 'sci.med']"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "We can now load the list of files matching those categories as follows:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 64,
            "metadata": {},
            "outputs": [],
            "source": [
                "from sklearn.datasets import fetch_20newsgroups\n",
                "\n",
                "twenty_train = fetch_20newsgroups(subset='train',\n",
                "     categories=categories, shuffle=True, random_state=42)"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "The returned dataset is a scikit-learn “bunch”: a simple holder object with fields that can be both accessed as python `dict` keys or `object` attributes for convenience. For example, the `target_names` holds the list of the requested category names (only four of the twenty because these are the ones we said should be fetched above):"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 65,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "['comp.graphics', 'comp.sys.mac.hardware', 'rec.sport.baseball', 'sci.med']"
                        ]
                    },
                    "execution_count": 65,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "# 获取类别名称，类别名称指在分类问题中，用于表示不同类别的可读标签\n",
                "# 提高可读性：将数值标签（如 0, 1, 2）转换为具体类别（如 \"cat\", \"dog\", \"bird\"）。\n",
                "twenty_train.target_names\n",
                "#  可以看到下面几种新闻的类型"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "The files themselves are loaded in memory in the `data` attribute:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 66,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Data 2353\n"
                    ]
                }
            ],
            "source": [
                "print(\"Data\", len(twenty_train.data))\n",
                "\n",
                "print(twenty_train.data[0])  # Print the first news article，这里是不包含label的"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "We can also get the filenames:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 67,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Filenames 2353\n"
                    ]
                }
            ],
            "source": [
                "print(\"Filenames\", len(twenty_train.filenames))"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Let’s print the first lines of the first loaded file and its label:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 68,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Label: sci.med\n",
                        "From: robin@ntmtv.com (Robin Coutellier)\n",
                        "Subject: Critique of Pressure Point Massager\n",
                        "Originator: robin@volans\n"
                    ]
                }
            ],
            "source": [
                "print(\"Label:\", twenty_train.target_names[twenty_train.target[0]])\n",
                "print(\"\\n\".join(twenty_train.data[0].split(\"\\n\")[:3]))"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Supervised learning algorithms will require a category label for each document in the training set. In this case, the category is the name of the newsgroup which also happens to be the name of the folder holding the individual documents.\n",
                "\n",
                "For speed and space efficiency reasons, scikit-learn loads the target attribute as an array of integers that corresponds to the index of the category name in the `target_names` list. The category integer id of each sample is stored in the `target` attribute:\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 69,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "array([3, 0, 1, 0, 2, 0, 0, 1, 3, 2])"
                        ]
                    },
                    "execution_count": 69,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "twenty_train.target[:10]"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "It is possible to get back the category names as follows:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 70,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "sci.med\n",
                        "comp.graphics\n",
                        "comp.sys.mac.hardware\n",
                        "comp.graphics\n",
                        "rec.sport.baseball\n",
                        "comp.graphics\n",
                        "comp.graphics\n",
                        "comp.sys.mac.hardware\n",
                        "sci.med\n",
                        "rec.sport.baseball\n"
                    ]
                }
            ],
            "source": [
                "for t in twenty_train.target[:10]:\n",
                "    print(twenty_train.target_names[t])"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "You might have noticed that the samples were shuffled randomly when we called `fetch_20newsgroups(..., shuffle=True, random_state=42)`: this is useful if you wish to select only a subset of samples to quickly train a model and get a first idea of the results before re-training on the complete dataset later.\n",
                "\n",
                "## Extracting features from text files\n",
                "\n",
                "In order to perform machine learning on text documents, we first need to turn the text content into a numerical representation (as discussed in lecture 1 and 2)."
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Bag of words\n",
                "\n",
                "We will start with the approach described in lecture 1: a bag of words:\n",
                "\n",
                "1. Assign a fixed integer id to each word occurring in any document of the training set (for instance by building a dictionary from words to integer indices).\n",
                "2. For each document `d` and each word `w`, count how often `w` appears in `d` and store the value in `X[d, w]`. Rather than the string representing the word, we will use its ID from the dictionary created in (1).\n",
                "\n",
                "We call each word a 'feature'. A typical vocabulary has over 100,000 words, so we will have a lot of features!\n",
                "\n",
                "If we have 10,000 samples, then storing `X` as a NumPy array of type float32 would require 10,000 x 100,000 x 4 bytes = 4GB of RAM.\n",
                "\n",
                "As discussed in lecture 1, many of these counts will be zero. In fact, our documents have at most a few thousand words, so the vast majority of the counts will be zero. We can describe the data as being high-dimensional sparse dataset.\n",
                "\n",
                "This was the motivation for the sparse storage methods discussed in lecture 1 and that are the focus of part of assignment 1. `scipy.sparse` matrices are data structures that do exactly what we need, and scikit-learn has built-in support for these structures.\n",
                "\n",
                "In the assignment, we don't let you use these libraries, so you can develop an intuition for how they work. In practise, you should not use your own implementation as other people have spent a lot of time optimising these implementations."
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Tokenising text with scikit-learn\n",
                "\n",
                "\n",
                "To count tokens we can use [CountVectorizer](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html#). As well as counting, it can also perfom a range of text processing steps, including tokenising text, filtering stopwords, ignoring very frequent or very rare features, and so on. It produces an object that can then transform a document into a feature vector.\n",
                "\n",
                "To explain these processing steps a little more:\n",
                "\n",
                "- _Tokenising_ is splitting a string into a series of individual tokens, e.g., `\"Hi there!\" -> [\"Hi\", \"there\", \"!\"]`. This is an essential step.\n",
                "- _Filtering stopwords_ is the removal of very common words, e.g., `[\"The\", \"book\", \"is\", \"good\"] -> [\"book\", \"good\"]`.  Note that this is not necessarily a good idea, depending on the application."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 71,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "(2353, 33868)"
                        ]
                    },
                    "execution_count": 71,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "from sklearn.feature_extraction.text import CountVectorizer\n",
                "count_vect = CountVectorizer()\n",
                "X_train_counts = count_vect.fit_transform(twenty_train.data)\n",
                "X_train_counts.shape"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "[CountVectorizer](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html#) supports counts of N-grams of words or characters. N-grams are when a sequence of consecutive items are treated as one item, e.g., the bigrams in the string `\"I like ice cream\"` are `\"I like\"`, `\"like ice\"`, and `\"ice cream\"`.\n",
                "\n",
                "Once fitted, the vectorizer has built a dictionary of feature indices:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 72,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "5071"
                        ]
                    },
                    "execution_count": 72,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "count_vect.vocabulary_.get(u'algorithm')"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "The index value of a word in the vocabulary is linked to its frequency in the whole training corpus.\n",
                "\n",
                "### TF-IDF\n",
                "\n",
                "As discussed in lecture 1, raw frequencies are often not quite what we want. We described the TF-IDF equation, which changes the value we store for a word, by (1) squashing the frequency, and (2) rescaling it depending on how many different documents the word appears in.\n",
                "\n",
                "TF-IDF can be computed using [TfidfTransformer](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfTransformer.html):\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 73,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "(2353, 33868)"
                        ]
                    },
                    "execution_count": 73,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "from sklearn.feature_extraction.text import TfidfTransformer\n",
                "tf_transformer = TfidfTransformer(use_idf=False).fit(X_train_counts)\n",
                "X_train_tf = tf_transformer.transform(X_train_counts)\n",
                "X_train_tf.shape"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "In the code above, we first use the `fit(..)` method to fit our estimator to the data and then use the `transform(..)` method to transform our count-matrix to a tf-idf representation.\n",
                "\n",
                "These two steps can be combined to achieve the same end result faster by using the `fit_transform(..)` method:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 74,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "(2353, 33868)"
                        ]
                    },
                    "execution_count": 74,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "tfidf_transformer = TfidfTransformer()\n",
                "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
                "X_train_tfidf.shape"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Training a classifier\n",
                "\n",
                "Now that we have our features, we can train a classifier to try to predict the category of a post. Let’s start with a [naïve Bayes](https://scikit-learn.org/stable/modules/naive_bayes.html#naive-bayes) classifier, which provides a nice baseline for this task. Note, naïve Bayeswas briefly mentioned in lecture 2, but you are not expected to understand the details of the method.\n",
                "\n",
                "scikit-learn includes several variants of naïve Bayes, and the one most suitable for word counts is the multinomial variant:\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 75,
            "metadata": {},
            "outputs": [],
            "source": [
                "from sklearn.naive_bayes import MultinomialNB\n",
                "clf = MultinomialNB().fit(X_train_tfidf, twenty_train.target)"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "To try to predict the outcome on a new document we need to extract the features using almost the same feature extracting steps as before. The difference is that we call `transform` instead of `fit_transform` on the transformers. `transform` applies the change to new data. `fit_transform` fits the parameters of the transformer:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 76,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "'God is love' => rec.sport.baseball\n",
                        "'OpenGL on the GPU is fast' => comp.graphics\n"
                    ]
                }
            ],
            "source": [
                "docs_new = ['God is love', 'OpenGL on the GPU is fast']\n",
                "X_new_counts = count_vect.transform(docs_new)\n",
                "X_new_tfidf = tfidf_transformer.transform(X_new_counts)\n",
                "\n",
                "predicted = clf.predict(X_new_tfidf)\n",
                "\n",
                "for doc, category in zip(docs_new, predicted):\n",
                "    print('%r => %s' % (doc, twenty_train.target_names[category]))"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Building a pipeline\n",
                "\n",
                "In order to make the vectorizer => transformer => classifier easier to work with, scikit-learn provides a [Pipeline](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html) class that behaves like a classifier, doing all of the steps together, passing the output of one as the input to the next:\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 77,
            "metadata": {},
            "outputs": [],
            "source": [
                "from sklearn.pipeline import Pipeline\n",
                "text_clf = Pipeline([\n",
                "    ('vect', CountVectorizer()),\n",
                "    ('tfidf', TfidfTransformer()),\n",
                "    ('clf', MultinomialNB()),\n",
                "])"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "The names `vect`, `tfidf` and `clf` (classifier) are arbitrary. We will use them to perform grid search for suitable hyperparameters below. We can now train the model with a single command:\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 78,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<style>#sk-container-id-3 {\n",
                            "  /* Definition of color scheme common for light and dark mode */\n",
                            "  --sklearn-color-text: black;\n",
                            "  --sklearn-color-line: gray;\n",
                            "  /* Definition of color scheme for unfitted estimators */\n",
                            "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
                            "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
                            "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
                            "  --sklearn-color-unfitted-level-3: chocolate;\n",
                            "  /* Definition of color scheme for fitted estimators */\n",
                            "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
                            "  --sklearn-color-fitted-level-1: #d4ebff;\n",
                            "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
                            "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
                            "\n",
                            "  /* Specific color for light theme */\n",
                            "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
                            "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
                            "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
                            "  --sklearn-color-icon: #696969;\n",
                            "\n",
                            "  @media (prefers-color-scheme: dark) {\n",
                            "    /* Redefinition of color scheme for dark theme */\n",
                            "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
                            "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
                            "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
                            "    --sklearn-color-icon: #878787;\n",
                            "  }\n",
                            "}\n",
                            "\n",
                            "#sk-container-id-3 {\n",
                            "  color: var(--sklearn-color-text);\n",
                            "}\n",
                            "\n",
                            "#sk-container-id-3 pre {\n",
                            "  padding: 0;\n",
                            "}\n",
                            "\n",
                            "#sk-container-id-3 input.sk-hidden--visually {\n",
                            "  border: 0;\n",
                            "  clip: rect(1px 1px 1px 1px);\n",
                            "  clip: rect(1px, 1px, 1px, 1px);\n",
                            "  height: 1px;\n",
                            "  margin: -1px;\n",
                            "  overflow: hidden;\n",
                            "  padding: 0;\n",
                            "  position: absolute;\n",
                            "  width: 1px;\n",
                            "}\n",
                            "\n",
                            "#sk-container-id-3 div.sk-dashed-wrapped {\n",
                            "  border: 1px dashed var(--sklearn-color-line);\n",
                            "  margin: 0 0.4em 0.5em 0.4em;\n",
                            "  box-sizing: border-box;\n",
                            "  padding-bottom: 0.4em;\n",
                            "  background-color: var(--sklearn-color-background);\n",
                            "}\n",
                            "\n",
                            "#sk-container-id-3 div.sk-container {\n",
                            "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
                            "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
                            "     so we also need the `!important` here to be able to override the\n",
                            "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
                            "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
                            "  display: inline-block !important;\n",
                            "  position: relative;\n",
                            "}\n",
                            "\n",
                            "#sk-container-id-3 div.sk-text-repr-fallback {\n",
                            "  display: none;\n",
                            "}\n",
                            "\n",
                            "div.sk-parallel-item,\n",
                            "div.sk-serial,\n",
                            "div.sk-item {\n",
                            "  /* draw centered vertical line to link estimators */\n",
                            "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
                            "  background-size: 2px 100%;\n",
                            "  background-repeat: no-repeat;\n",
                            "  background-position: center center;\n",
                            "}\n",
                            "\n",
                            "/* Parallel-specific style estimator block */\n",
                            "\n",
                            "#sk-container-id-3 div.sk-parallel-item::after {\n",
                            "  content: \"\";\n",
                            "  width: 100%;\n",
                            "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
                            "  flex-grow: 1;\n",
                            "}\n",
                            "\n",
                            "#sk-container-id-3 div.sk-parallel {\n",
                            "  display: flex;\n",
                            "  align-items: stretch;\n",
                            "  justify-content: center;\n",
                            "  background-color: var(--sklearn-color-background);\n",
                            "  position: relative;\n",
                            "}\n",
                            "\n",
                            "#sk-container-id-3 div.sk-parallel-item {\n",
                            "  display: flex;\n",
                            "  flex-direction: column;\n",
                            "}\n",
                            "\n",
                            "#sk-container-id-3 div.sk-parallel-item:first-child::after {\n",
                            "  align-self: flex-end;\n",
                            "  width: 50%;\n",
                            "}\n",
                            "\n",
                            "#sk-container-id-3 div.sk-parallel-item:last-child::after {\n",
                            "  align-self: flex-start;\n",
                            "  width: 50%;\n",
                            "}\n",
                            "\n",
                            "#sk-container-id-3 div.sk-parallel-item:only-child::after {\n",
                            "  width: 0;\n",
                            "}\n",
                            "\n",
                            "/* Serial-specific style estimator block */\n",
                            "\n",
                            "#sk-container-id-3 div.sk-serial {\n",
                            "  display: flex;\n",
                            "  flex-direction: column;\n",
                            "  align-items: center;\n",
                            "  background-color: var(--sklearn-color-background);\n",
                            "  padding-right: 1em;\n",
                            "  padding-left: 1em;\n",
                            "}\n",
                            "\n",
                            "\n",
                            "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
                            "clickable and can be expanded/collapsed.\n",
                            "- Pipeline and ColumnTransformer use this feature and define the default style\n",
                            "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
                            "*/\n",
                            "\n",
                            "/* Pipeline and ColumnTransformer style (default) */\n",
                            "\n",
                            "#sk-container-id-3 div.sk-toggleable {\n",
                            "  /* Default theme specific background. It is overwritten whether we have a\n",
                            "  specific estimator or a Pipeline/ColumnTransformer */\n",
                            "  background-color: var(--sklearn-color-background);\n",
                            "}\n",
                            "\n",
                            "/* Toggleable label */\n",
                            "#sk-container-id-3 label.sk-toggleable__label {\n",
                            "  cursor: pointer;\n",
                            "  display: block;\n",
                            "  width: 100%;\n",
                            "  margin-bottom: 0;\n",
                            "  padding: 0.5em;\n",
                            "  box-sizing: border-box;\n",
                            "  text-align: center;\n",
                            "}\n",
                            "\n",
                            "#sk-container-id-3 label.sk-toggleable__label-arrow:before {\n",
                            "  /* Arrow on the left of the label */\n",
                            "  content: \"▸\";\n",
                            "  float: left;\n",
                            "  margin-right: 0.25em;\n",
                            "  color: var(--sklearn-color-icon);\n",
                            "}\n",
                            "\n",
                            "#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {\n",
                            "  color: var(--sklearn-color-text);\n",
                            "}\n",
                            "\n",
                            "/* Toggleable content - dropdown */\n",
                            "\n",
                            "#sk-container-id-3 div.sk-toggleable__content {\n",
                            "  max-height: 0;\n",
                            "  max-width: 0;\n",
                            "  overflow: hidden;\n",
                            "  text-align: left;\n",
                            "  /* unfitted */\n",
                            "  background-color: var(--sklearn-color-unfitted-level-0);\n",
                            "}\n",
                            "\n",
                            "#sk-container-id-3 div.sk-toggleable__content.fitted {\n",
                            "  /* fitted */\n",
                            "  background-color: var(--sklearn-color-fitted-level-0);\n",
                            "}\n",
                            "\n",
                            "#sk-container-id-3 div.sk-toggleable__content pre {\n",
                            "  margin: 0.2em;\n",
                            "  border-radius: 0.25em;\n",
                            "  color: var(--sklearn-color-text);\n",
                            "  /* unfitted */\n",
                            "  background-color: var(--sklearn-color-unfitted-level-0);\n",
                            "}\n",
                            "\n",
                            "#sk-container-id-3 div.sk-toggleable__content.fitted pre {\n",
                            "  /* unfitted */\n",
                            "  background-color: var(--sklearn-color-fitted-level-0);\n",
                            "}\n",
                            "\n",
                            "#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
                            "  /* Expand drop-down */\n",
                            "  max-height: 200px;\n",
                            "  max-width: 100%;\n",
                            "  overflow: auto;\n",
                            "}\n",
                            "\n",
                            "#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
                            "  content: \"▾\";\n",
                            "}\n",
                            "\n",
                            "/* Pipeline/ColumnTransformer-specific style */\n",
                            "\n",
                            "#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
                            "  color: var(--sklearn-color-text);\n",
                            "  background-color: var(--sklearn-color-unfitted-level-2);\n",
                            "}\n",
                            "\n",
                            "#sk-container-id-3 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
                            "  background-color: var(--sklearn-color-fitted-level-2);\n",
                            "}\n",
                            "\n",
                            "/* Estimator-specific style */\n",
                            "\n",
                            "/* Colorize estimator box */\n",
                            "#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
                            "  /* unfitted */\n",
                            "  background-color: var(--sklearn-color-unfitted-level-2);\n",
                            "}\n",
                            "\n",
                            "#sk-container-id-3 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
                            "  /* fitted */\n",
                            "  background-color: var(--sklearn-color-fitted-level-2);\n",
                            "}\n",
                            "\n",
                            "#sk-container-id-3 div.sk-label label.sk-toggleable__label,\n",
                            "#sk-container-id-3 div.sk-label label {\n",
                            "  /* The background is the default theme color */\n",
                            "  color: var(--sklearn-color-text-on-default-background);\n",
                            "}\n",
                            "\n",
                            "/* On hover, darken the color of the background */\n",
                            "#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {\n",
                            "  color: var(--sklearn-color-text);\n",
                            "  background-color: var(--sklearn-color-unfitted-level-2);\n",
                            "}\n",
                            "\n",
                            "/* Label box, darken color on hover, fitted */\n",
                            "#sk-container-id-3 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
                            "  color: var(--sklearn-color-text);\n",
                            "  background-color: var(--sklearn-color-fitted-level-2);\n",
                            "}\n",
                            "\n",
                            "/* Estimator label */\n",
                            "\n",
                            "#sk-container-id-3 div.sk-label label {\n",
                            "  font-family: monospace;\n",
                            "  font-weight: bold;\n",
                            "  display: inline-block;\n",
                            "  line-height: 1.2em;\n",
                            "}\n",
                            "\n",
                            "#sk-container-id-3 div.sk-label-container {\n",
                            "  text-align: center;\n",
                            "}\n",
                            "\n",
                            "/* Estimator-specific */\n",
                            "#sk-container-id-3 div.sk-estimator {\n",
                            "  font-family: monospace;\n",
                            "  border: 1px dotted var(--sklearn-color-border-box);\n",
                            "  border-radius: 0.25em;\n",
                            "  box-sizing: border-box;\n",
                            "  margin-bottom: 0.5em;\n",
                            "  /* unfitted */\n",
                            "  background-color: var(--sklearn-color-unfitted-level-0);\n",
                            "}\n",
                            "\n",
                            "#sk-container-id-3 div.sk-estimator.fitted {\n",
                            "  /* fitted */\n",
                            "  background-color: var(--sklearn-color-fitted-level-0);\n",
                            "}\n",
                            "\n",
                            "/* on hover */\n",
                            "#sk-container-id-3 div.sk-estimator:hover {\n",
                            "  /* unfitted */\n",
                            "  background-color: var(--sklearn-color-unfitted-level-2);\n",
                            "}\n",
                            "\n",
                            "#sk-container-id-3 div.sk-estimator.fitted:hover {\n",
                            "  /* fitted */\n",
                            "  background-color: var(--sklearn-color-fitted-level-2);\n",
                            "}\n",
                            "\n",
                            "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
                            "\n",
                            "/* Common style for \"i\" and \"?\" */\n",
                            "\n",
                            ".sk-estimator-doc-link,\n",
                            "a:link.sk-estimator-doc-link,\n",
                            "a:visited.sk-estimator-doc-link {\n",
                            "  float: right;\n",
                            "  font-size: smaller;\n",
                            "  line-height: 1em;\n",
                            "  font-family: monospace;\n",
                            "  background-color: var(--sklearn-color-background);\n",
                            "  border-radius: 1em;\n",
                            "  height: 1em;\n",
                            "  width: 1em;\n",
                            "  text-decoration: none !important;\n",
                            "  margin-left: 1ex;\n",
                            "  /* unfitted */\n",
                            "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
                            "  color: var(--sklearn-color-unfitted-level-1);\n",
                            "}\n",
                            "\n",
                            ".sk-estimator-doc-link.fitted,\n",
                            "a:link.sk-estimator-doc-link.fitted,\n",
                            "a:visited.sk-estimator-doc-link.fitted {\n",
                            "  /* fitted */\n",
                            "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
                            "  color: var(--sklearn-color-fitted-level-1);\n",
                            "}\n",
                            "\n",
                            "/* On hover */\n",
                            "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
                            ".sk-estimator-doc-link:hover,\n",
                            "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
                            ".sk-estimator-doc-link:hover {\n",
                            "  /* unfitted */\n",
                            "  background-color: var(--sklearn-color-unfitted-level-3);\n",
                            "  color: var(--sklearn-color-background);\n",
                            "  text-decoration: none;\n",
                            "}\n",
                            "\n",
                            "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
                            ".sk-estimator-doc-link.fitted:hover,\n",
                            "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
                            ".sk-estimator-doc-link.fitted:hover {\n",
                            "  /* fitted */\n",
                            "  background-color: var(--sklearn-color-fitted-level-3);\n",
                            "  color: var(--sklearn-color-background);\n",
                            "  text-decoration: none;\n",
                            "}\n",
                            "\n",
                            "/* Span, style for the box shown on hovering the info icon */\n",
                            ".sk-estimator-doc-link span {\n",
                            "  display: none;\n",
                            "  z-index: 9999;\n",
                            "  position: relative;\n",
                            "  font-weight: normal;\n",
                            "  right: .2ex;\n",
                            "  padding: .5ex;\n",
                            "  margin: .5ex;\n",
                            "  width: min-content;\n",
                            "  min-width: 20ex;\n",
                            "  max-width: 50ex;\n",
                            "  color: var(--sklearn-color-text);\n",
                            "  box-shadow: 2pt 2pt 4pt #999;\n",
                            "  /* unfitted */\n",
                            "  background: var(--sklearn-color-unfitted-level-0);\n",
                            "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
                            "}\n",
                            "\n",
                            ".sk-estimator-doc-link.fitted span {\n",
                            "  /* fitted */\n",
                            "  background: var(--sklearn-color-fitted-level-0);\n",
                            "  border: var(--sklearn-color-fitted-level-3);\n",
                            "}\n",
                            "\n",
                            ".sk-estimator-doc-link:hover span {\n",
                            "  display: block;\n",
                            "}\n",
                            "\n",
                            "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
                            "\n",
                            "#sk-container-id-3 a.estimator_doc_link {\n",
                            "  float: right;\n",
                            "  font-size: 1rem;\n",
                            "  line-height: 1em;\n",
                            "  font-family: monospace;\n",
                            "  background-color: var(--sklearn-color-background);\n",
                            "  border-radius: 1rem;\n",
                            "  height: 1rem;\n",
                            "  width: 1rem;\n",
                            "  text-decoration: none;\n",
                            "  /* unfitted */\n",
                            "  color: var(--sklearn-color-unfitted-level-1);\n",
                            "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
                            "}\n",
                            "\n",
                            "#sk-container-id-3 a.estimator_doc_link.fitted {\n",
                            "  /* fitted */\n",
                            "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
                            "  color: var(--sklearn-color-fitted-level-1);\n",
                            "}\n",
                            "\n",
                            "/* On hover */\n",
                            "#sk-container-id-3 a.estimator_doc_link:hover {\n",
                            "  /* unfitted */\n",
                            "  background-color: var(--sklearn-color-unfitted-level-3);\n",
                            "  color: var(--sklearn-color-background);\n",
                            "  text-decoration: none;\n",
                            "}\n",
                            "\n",
                            "#sk-container-id-3 a.estimator_doc_link.fitted:hover {\n",
                            "  /* fitted */\n",
                            "  background-color: var(--sklearn-color-fitted-level-3);\n",
                            "}\n",
                            "</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;vect&#x27;, CountVectorizer()), (&#x27;tfidf&#x27;, TfidfTransformer()),\n",
                            "                (&#x27;clf&#x27;, MultinomialNB())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;Pipeline<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.pipeline.Pipeline.html\">?<span>Documentation for Pipeline</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>Pipeline(steps=[(&#x27;vect&#x27;, CountVectorizer()), (&#x27;tfidf&#x27;, TfidfTransformer()),\n",
                            "                (&#x27;clf&#x27;, MultinomialNB())])</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;CountVectorizer<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html\">?<span>Documentation for CountVectorizer</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>CountVectorizer()</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;TfidfTransformer<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.feature_extraction.text.TfidfTransformer.html\">?<span>Documentation for TfidfTransformer</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>TfidfTransformer()</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;MultinomialNB<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.naive_bayes.MultinomialNB.html\">?<span>Documentation for MultinomialNB</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>MultinomialNB()</pre></div> </div></div></div></div></div></div>"
                        ],
                        "text/plain": [
                            "Pipeline(steps=[('vect', CountVectorizer()), ('tfidf', TfidfTransformer()),\n",
                            "                ('clf', MultinomialNB())])"
                        ]
                    },
                    "execution_count": 78,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "text_clf.fit(twenty_train.data, twenty_train.target)"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Evaluation of the performance on the test set\n",
                "\n",
                "Now we will get the test data, which the model has not seen, and use it to measure how accurate the model is:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 79,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "np.float64(0.9329929802169751)"
                        ]
                    },
                    "execution_count": 79,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "import numpy as np\n",
                "twenty_test = fetch_20newsgroups(subset='test',\n",
                "    categories=categories, shuffle=True, random_state=42)\n",
                "docs_test = twenty_test.data\n",
                "predicted = text_clf.predict(docs_test)\n",
                "np.mean(predicted == twenty_test.target)"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "We achieved 93.3% accuracy. Let’s see if we can do better with a linear [support vector machine (SVM)](https://scikit-learn.org/stable/modules/svm.html#svm), which is widely regarded as one of the best linear text classification algorithms (although it’s also a bit slower than naïve Bayes). We can change the learner by simply plugging a different classifier object into our pipeline:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 80,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "np.float64(0.9432035737077218)"
                        ]
                    },
                    "execution_count": 80,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "from sklearn.linear_model import SGDClassifier\n",
                "text_clf = Pipeline([\n",
                "    ('vect', CountVectorizer()),\n",
                "    ('tfidf', TfidfTransformer()),\n",
                "    ('clf', SGDClassifier(loss='hinge', penalty='l2',\n",
                "                          alpha=1e-3, random_state=42,\n",
                "                          max_iter=5, tol=None)),\n",
                "])\n",
                "\n",
                "text_clf.fit(twenty_train.data, twenty_train.target)\n",
                "predicted = text_clf.predict(docs_test)\n",
                "np.mean(predicted == twenty_test.target)"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "We achieved 94.3% accuracy using the SVM. scikit-learn provides further utilities for more detailed performance analysis of the results:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 81,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "                       precision    recall  f1-score   support\n",
                        "\n",
                        "        comp.graphics       0.92      0.92      0.92       389\n",
                        "comp.sys.mac.hardware       0.95      0.95      0.95       385\n",
                        "   rec.sport.baseball       0.94      0.99      0.97       397\n",
                        "              sci.med       0.97      0.92      0.94       396\n",
                        "\n",
                        "             accuracy                           0.94      1567\n",
                        "            macro avg       0.94      0.94      0.94      1567\n",
                        "         weighted avg       0.94      0.94      0.94      1567\n",
                        "\n"
                    ]
                }
            ],
            "source": [
                "from sklearn import metrics\n",
                "print(metrics.classification_report(twenty_test.target, predicted,\n",
                "    target_names=twenty_test.target_names))"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "These metrics are as described in lecture 2.\n",
                "\n",
                "We can see that we are doing slightly better on baseball.\n",
                "\n",
                "Now let's look at the confusion matrix"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 82,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "array([[358,  12,  10,   9],\n",
                            "       [ 10, 364,   8,   3],\n",
                            "       [  0,   3, 393,   1],\n",
                            "       [ 22,   5,   6, 363]])"
                        ]
                    },
                    "execution_count": 82,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "metrics.confusion_matrix(twenty_test.target, predicted)"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Baseball is very different from medicine and computer related documents, so it is rarely confused for them (see the third row and column). The two computer related ones are easy to confuse."
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Hyperparameter tuning using grid search\n",
                "\n",
                "We’ve already encountered some hyperparameters such as `use_idf` in the `TfidfTransformer`. Classifiers tend to have many hyperparameters as well; e.g., `MultinomialNB` includes a smoothing hyperparameter `alpha`, and `SGDClassifier` has a penalty hyperparameter `alpha` and configurable loss and penalty terms in the objective function (see the module documentation, or use the Python `help(...)` function to get a description of these).\n",
                "\n",
                "We could manually try various settings of these hyperparameters to find the configuration that leads to the best results. That would be a lot of effort though. Instead, we can automatically search through a range of combinations of options. The simplest search is a grid search. \n",
                "\n",
                "Let's try out using (a) either words or bigrams, (b) with or without idf, and (c) with a penalty parameter of either 0.01 or 0.001 for the linear SVM:\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 83,
            "metadata": {},
            "outputs": [],
            "source": [
                "from sklearn.model_selection import GridSearchCV\n",
                "parameters = {\n",
                "    'vect__ngram_range': [(1, 1), (1, 2)],\n",
                "    'tfidf__use_idf': (True, False),\n",
                "    'clf__alpha': (1e-2, 1e-3),\n",
                "}"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "The more options you consider, the more effort this search will involve. In this case we are considering 2x2x2 = 8 combinations.\n",
                "\n",
                "If we have multiple CPU cores at our disposal, we can tell the grid searcher to try these eight parameter combinations in parallel by using the `n_jobs` parameter. If we give this parameter a value of `-1`, grid search will detect how many cores are installed and use them all.\n",
                "\n",
                "When running this in Ed, we use just 1 core, but you can use more on your own machine."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 84,
            "metadata": {},
            "outputs": [],
            "source": [
                "gs_clf = GridSearchCV(text_clf, parameters, cv=5, n_jobs=1)"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "The grid search instance behaves like a normal scikit-learn model. Let’s perform the search on a smaller subset of the training data to speed up the computation:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 85,
            "metadata": {},
            "outputs": [],
            "source": [
                "gs_clf = gs_clf.fit(twenty_train.data[:400], twenty_train.target[:400])"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "The result of calling `fit` on a `GridSearchCV` object is a classifier that we can use to run `predict` to get a guess at the answer for an input:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 86,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "'comp.sys.mac.hardware'"
                        ]
                    },
                    "execution_count": 86,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "twenty_train.target_names[gs_clf.predict(['Computers are cool'])[0]]"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "The object’s `best_score_` and `best_params_` attributes store the best mean score and the parameters setting corresponding to that score:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 87,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "clf__alpha: 0.001\n",
                        "tfidf__use_idf: True\n",
                        "vect__ngram_range: (1, 1)\n"
                    ]
                }
            ],
            "source": [
                "gs_clf.best_score_\n",
                "for param_name in sorted(parameters.keys()):\n",
                "    print(\"%s: %r\" % (param_name, gs_clf.best_params_[param_name]))"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "A more detailed summary of the search is available at `gs_clf.cv_results_`.\n",
                "\n",
                "The `cv_results_` parameter can be imported into pandas as a DataFrame for further inspection."
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Your done with the pre-work part of this workshop!"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3 (ipykernel)",
            "language": "python",
            "name": "python3"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
