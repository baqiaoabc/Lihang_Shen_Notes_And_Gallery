{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AoFBBPWe7Ztv"
      },
      "source": [
        "# Identifying Deception in Diplomacy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MLFYhPLK8FAd"
      },
      "source": [
        "In the workshop, you will use scikit-learn to identify deception in the board game Diplomacy.\n",
        "\n",
        "First, form a pair to do these tasks. You should have just one computer and one person typing at a time.\n",
        "\n",
        "Next, please reset this lesson to the scaffold, to ensure you have the latest version of the data.\n",
        "\n",
        "**You are welcome to download and run this notebook somewhere else** (e.g., on your local computer). If you do, you will need to have scikit-learn installed.\n",
        "\n",
        "We will be using the data from this repository: https://github.com/DenisPeskoff/2020_acl_diplomacy. If you are curious about where this comes from, see the research paper: https://aclanthology.org/2020.acl-main.353/\n",
        "\n",
        "The data contains JSON lines like this:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SOF2VM_48GMg"
      },
      "source": [
        "```python\n",
        "{\n",
        "    \"messages\": [\n",
        "        \"Germany!\\n\\nJust the person I want to speak with. I have a somewhat crazy idea that I\\u2019ve always wanted to try with I/G, but I\\u2019ve never actually convinced the other guy to try it. And, what\\u2019s worse, it might make you suspicious of me. \\n\\nSo...do I suggest it?\\n\\nI\\u2019m thinking that this is a low stakes game, not a tournament or anything, and an interesting and unusual move set might make it more fun? That\\u2019s my hope anyway.\\n\\nWhat is your appetite like for unusual and crazy?\",\n",
        "        \"You've whet my appetite, Italy. What's the suggestion?\",\n",
        "        \"\\ud83d\\udc4d\",\n",
        "        \"It seems like there are a lot of ways that could go wrong...I don't see why France would see you approaching/taking Munich--while I do nothing about it--and not immediately feel skittish\",\n",
        "        \"Yeah, I can\\u2019t say I\\u2019ve tried it and it works, cause I\\u2019ve never tried it or seen it. But how I think it would work is (a) my Spring move looks like an attack on Austria, so it would not be surprising if you did not cover Munich. Then (b) you build two armies, which looks like we\\u2019re really at war and you\\u2019re going to eject me. Then we launch the attack in Spring. So there is really no part of this that would raise alarm bells with France.\\n\\nAll that said, I\\u2019ve literally never done it before, and it does involve risk for you, so I\\u2019m not offended or concerned if it\\u2019s just not for you. I\\u2019m happy to play more conventionally too. Up to you.\",\n",
        "        \"I am just sensing that you don\\u2019t like this idea, so shall we talk about something else? That was just a crazy idea I\\u2019ve always wanted to try. I\\u2019m happy to play more conservatively.\",\n",
        "        \"Any thoughts?\",\n",
        "        \"Sorry Italy I've been away doing, um, German things. Brewing Lagers?\",\n",
        "        \"I don't think I'm ready to go for that idea, however I'd be down for some good ol'-fashioned Austria-kicking?\",\n",
        "        \"I am pretty conflicted about whether to guess that you were telling the truth or lying about the \\u201cbrewing lagers\\u201d thing. I am going to take it literally and say \\ud83d\\udc4e even though I don\\u2019t think you meant it deceptively. \\ud83d\\ude09\"\n",
        "    ],\n",
        "    \"sender_labels\": [ true, true, true, true, true, true, true, true, true, true ],\n",
        "    \n",
        "    # The rest of these fields are not needed in the first task\n",
        "    \"receiver_labels\": [ true, true, true, true, \"NOANNOTATION\", \"NOANNOTATION\", \"NOANNOTATION\", true, false, true ],\n",
        "    \"speakers\": [ \"italy\", \"germany\", \"italy\", \"germany\", \"italy\", \"italy\", \"italy\", \"germany\", \"germany\", \"italy\" ],\n",
        "    \"receivers\": [ \"germany\", \"italy\", \"germany\", \"italy\", \"germany\", \"germany\", \"germany\", \"italy\", \"italy\", \"germany\" ],\n",
        "    \"absolute_message_index\": [ 74, 76, 86, 87, 89, 92, 97, 117, 119, 121, ],\n",
        "    \"relative_message_index\": [ 0, 1, 2, 3, 4, 5, 6, 7, 8, 9 ],\n",
        "    \"seasons\": [ \"Spring\", \"Spring\", \"Spring\", \"Spring\", \"Spring\", \"Spring\", \"Spring\", \"Spring\", \"Spring\", \"Spring\", ],\n",
        "    \"years\": [ \"1901\", \"1901\", \"1901\", \"1901\", \"1901\", \"1901\", \"1901\", \"1901\", \"1901\", \"1901\" ],\n",
        "    \"game_score\": [ \"3\", \"3\", \"3\", \"3\", \"3\", \"3\", \"3\", \"3\", \"3\", \"3\" ],\n",
        "    \"game_score_delta\": [ \"0\", \"0\", \"0\", \"0\", \"0\", \"0\", \"0\", \"0\", \"0\", \"0\" ],\n",
        "    \"players\": [ \"italy\", \"germany\" ],\n",
        "    \"game_id\": 1\n",
        "}\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VJ2GRcmW8GPI"
      },
      "source": [
        "For us, the crucial thing to know about is:\n",
        "\n",
        "- `messages`, the text being sent back and forth between players\n",
        "- `sender_labels`, this indicates whether the message is truthful (`true`) or not (`false`)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I6II9hu67_IM"
      },
      "source": [
        "## Task 1: Basic Classifier\n",
        "Implement a Logistic Regression classifier that predicts if a message is truthful. The reason we are using logistic regression is that it is widely used and a great baseline for many NLP classification tasks. You should use the following configuration:\n",
        "\n",
        "- Solver: `saga`\n",
        "- Penalty: `None`\n",
        "- All other parameters as defaults\n",
        "\n",
        "The steps you will need to implement are:\n",
        "\n",
        "1. **Data Loading**: Start by loading your training, development, and test datasets to prepare the features (messages) and labels (sender_labels).\n",
        "2. **Data Preprocessing**: Convert the text messages into a suitable format for modelling, using the same approach as in the tutorial above.\n",
        "3. **Model Definition**: Use scikit-learn's LogisticRegression class to create the model, with the solver set to 'saga' and penalty set to 'None'.\n",
        "4. **Model Training**: Train your model using the training data.\n",
        "5. **Model Evaluation**: Assess the model's performance on the development dataset.\n",
        "\n",
        "A few notes that may be helpful:\n",
        "\n",
        "- In the notebook above, `twenty_train.data` is a list of strings. You can create something comparable yourself for the diplomacy data\n",
        "- In the notebook above, `twenty_train.target` is a Numpy array. You can create a regular Python list and then convert it into an array with `numpy.array(my_list)`\n",
        "\n",
        "You should get results that look something like this (where `0` indicates a lie and `1` indicates the truth):"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PMQ5xkop8xMm"
      },
      "source": [
        "```python\n",
        "              precision    recall  f1-score   support\n",
        "\n",
        "           0       0.07      0.04      0.05       124\n",
        "           1       0.96      0.97      0.96      2658\n",
        "\n",
        "    accuracy                           0.93      2782\n",
        "   macro avg       0.51      0.51      0.51      2782\n",
        "weighted avg       0.92      0.93      0.92      2782\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q40EXVXZ814W"
      },
      "source": [
        "The number we care about here is the `f1-score` for `0`, ie., how well are we doing at identifying lies? This simple model scores `0.05`, which is not very good - it's hard!\n",
        "\n",
        "Note also that `accuracy` will look high (`0.93` above). That's because it's very easy to get a lot of the test cases correct by predicting they are not lies."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rxT1sTWB7bN2",
        "outputId": "b370fb18-7cc1-4b2c-c516-23fe4234ac45"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.9317038102084831\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.07      0.04      0.05       124\n",
            "           1       0.96      0.97      0.96      2658\n",
            "\n",
            "    accuracy                           0.93      2782\n",
            "   macro avg       0.51      0.51      0.51      2782\n",
            "weighted avg       0.92      0.93      0.92      2782\n",
            "\n",
            "[[   5  119]\n",
            " [  71 2587]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn import metrics\n",
        "\n",
        "\n",
        "def readfile(filename):\n",
        "    examples_msg = []\n",
        "    examples_label = []\n",
        "    # 只有jsonl可以按行读取\n",
        "    for line in open(filename):\n",
        "        # 去掉行首尾空白字符（如换行符），然后使用 json.loads() 将这一行解析成 Python 字典。\n",
        "        data = json.loads(line.strip())\n",
        "        for msg, tlabel in zip(data['messages'], data['sender_labels']):\n",
        "            examples_msg.append(msg)\n",
        "            examples_label.append(1 if tlabel else 0)\n",
        "    return examples_msg, np.array(examples_label)\n",
        "\n",
        "\n",
        "train = readfile(\"mod-train.jsonl\")\n",
        "valid = readfile(\"mod-validation.jsonl\")\n",
        "\n",
        "text_clf = Pipeline([                                           \n",
        "    ('vect', CountVectorizer()),\n",
        "    ('tfidf', TfidfTransformer()), # 把上面的词频矩阵，转换成 TF-IDF 权重矩阵。强调更“有信息量”的词（减少高频但无意义的停用词影响）。\n",
        "    ('clf', LogisticRegression(penalty=None, solver='saga', max_iter=100, random_state=42)),\n",
        "])\n",
        "text_clf.fit(train[0], train[1])\n",
        "\n",
        "predicted = text_clf.predict(valid[0])\n",
        "\n",
        "# predicted == valid[1] 是一个逐元素的比较操作，返回一个布尔数组，表示每个位置上的预测结果是否与实际标签相等。\n",
        "# 比如，如果 predicted 和 valid[1] 在第一个位置上的值相等，则结果是 True，否则是 False。接着，np.mean(predicted == valid[1]) \n",
        "# 计算这个布尔数组的平均值。由于 True 被视为 1，False 被视为 0，np.mean 会返回一个介于 0 和 1 之间的值\n",
        "print(np.mean(predicted == valid[1]))\n",
        "\n",
        "print(metrics.classification_report(valid[1], predicted))\n",
        "print(metrics.confusion_matrix(valid[1], predicted))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2kpMxqWk7rr9"
      },
      "source": [
        "## Task 2: Analysis\n",
        "Below, we will explore improving the classifier, but first, investigate a few properties of the dataset:\n",
        "\n",
        "1. How accurate are people? The receiver_labels field contains whether the receiver of the message thought it was the truth (`true`) or not (`false`). For cases where they did not provide a label (`NOANNOTATION`), treat it as `true`, i.e., as if they thought the message was truthful. Calculate the precision and recall of the receivers.\n",
        "\n",
        "2. Above we just used the text, but there is more information available. For each of the following fields, calculate the percentage of messages that are lies for each possible value: `speakers`, `receivers`, pairs of (`speakers`, `receivers`), `seasons`, `years`.\n",
        "\n",
        "3. Read through 20 of the training set messages that are lies and 20 that are the truth. Do you notice anything different about them?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HXqbXGK6GaIt"
      },
      "source": [
        "### Item 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f09M53t47eKD"
      },
      "outputs": [],
      "source": [
        "# 回答问题1 用来计算接收者（receiver）标签的准确性，也就是 接收者是否认为信息是正确的。\n",
        "# 这里我们通过计算 接收者标签的精度（precision）和召回率（recall） 来评估接收者判断的准确性。\n",
        "def readfile_v2(filename):\n",
        "    examples_label_sender = []\n",
        "    examples_label_receiver = []\n",
        "    for line in open(filename):\n",
        "        data = json.loads(line.strip())\n",
        "        for tlabel, rlabel in zip(data['sender_labels'], data['receiver_labels']):\n",
        "            examples_label_sender.append(1 if tlabel else 0)\n",
        "            examples_label_receiver.append(1 if rlabel != False else 0)\n",
        "    return np.array(examples_label_sender), np.array(examples_label_receiver)\n",
        "\n",
        "\n",
        "train_v2 = readfile_v2(\"mod-train.jsonl\")\n",
        "valid_v2 = readfile_v2(\"mod-validation.jsonl\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mhaRf_MX9Zs7",
        "outputId": "0a343b30-3b6d-4623-fef2-b6a2a6a2f68e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.9284687275341481\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.04      0.06      0.05        85\n",
            "           1       0.97      0.96      0.96      2697\n",
            "\n",
            "    accuracy                           0.93      2782\n",
            "   macro avg       0.51      0.51      0.51      2782\n",
            "weighted avg       0.94      0.93      0.93      2782\n",
            "\n",
            "[[   5   80]\n",
            " [ 119 2578]]\n"
          ]
        }
      ],
      "source": [
        "print(np.mean(valid_v2[0] == valid_v2[1]))\n",
        "print(metrics.classification_report(valid_v2[1], valid_v2[0]))\n",
        "print(metrics.confusion_matrix(valid_v2[1], valid_v2[0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CB7YYY5K9ZxW",
        "outputId": "fbc42524-b388-4239-f687-1743e67a0bf5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.921553629100799\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.12      0.12      0.12       528\n",
            "           1       0.96      0.96      0.96     11238\n",
            "\n",
            "    accuracy                           0.92     11766\n",
            "   macro avg       0.54      0.54      0.54     11766\n",
            "weighted avg       0.92      0.92      0.92     11766\n",
            "\n",
            "[[   64   464]\n",
            " [  459 10779]]\n"
          ]
        }
      ],
      "source": [
        "print(np.mean(train_v2[0] == train_v2[1]))\n",
        "print(metrics.classification_report(train_v2[1], train_v2[0]))\n",
        "print(metrics.confusion_matrix(train_v2[1], train_v2[0]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2yh-0F0wGby-"
      },
      "source": [
        "### Item 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mMnfoqSuDBKm"
      },
      "outputs": [],
      "source": [
        "# 为了计算每个字段（或其每个可能值）对应的谎言的比例，\n",
        "\n",
        "def readfile_full(filename):\n",
        "    examples_label_sender = []\n",
        "    speakers_ = []\n",
        "    receivers_ = []\n",
        "    speakers_and_receivers_ = []\n",
        "    seasons_ = []\n",
        "    years_ = []\n",
        "    for line in open(filename):\n",
        "        data = json.loads(line.strip())\n",
        "        for tlabel, speakers, receivers, seasons, years in zip(data['sender_labels'], data['speakers'], data['receivers'], data['seasons'], data['years']):\n",
        "            examples_label_sender.append(1 if tlabel else 0)\n",
        "            speakers_.append(speakers)\n",
        "            receivers_.append(receivers)\n",
        "            speakers_and_receivers_.append((speakers, receivers))\n",
        "            seasons_.append(seasons)\n",
        "            years_.append(years)\n",
        "    return np.array(examples_label_sender), speakers_, receivers_, speakers_and_receivers_, seasons_, years_\n",
        "\n",
        "\n",
        "train_full = readfile_full(\"mod-train.jsonl\")\n",
        "valid_full = readfile_full(\"mod-validation.jsonl\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ao6VkrSfDBM7"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import json\n",
        "from collections import defaultdict\n",
        "\n",
        "def compute_lie_percentages(labels, values):\n",
        "    \"\"\"\n",
        "    Compute the percentage of messages that are lies (0) for each unique value in a given field.\n",
        "\n",
        "    :param labels: List of binary labels (1 = truth, 0 = lie)\n",
        "    :param values: List of categorical values (e.g., speakers, receivers)\n",
        "    :return: Dictionary with percentage of lies for each unique value\n",
        "    \"\"\"\n",
        "    total_counts = defaultdict(int)\n",
        "    lie_counts = defaultdict(int)\n",
        "\n",
        "    for label, value in zip(labels, values):\n",
        "        total_counts[value] += 1\n",
        "        if label == 0:\n",
        "            lie_counts[value] += 1\n",
        "\n",
        "    percentages = {key: (lie_counts[key] / total_counts[key]) * 100 for key in total_counts}\n",
        "    return percentages\n",
        "\n",
        "def compute_lie_percentages_for_all(train_data):\n",
        "    \"\"\"\n",
        "    Computes lie percentages for speakers, receivers, (speakers, receivers) pairs, seasons, and years.\n",
        "    \"\"\"\n",
        "    labels, speakers, receivers, speakers_receivers, seasons, years = train_data\n",
        "\n",
        "    # Compute lie percentages\n",
        "    speaker_lie_percent = compute_lie_percentages(labels, speakers)\n",
        "    receiver_lie_percent = compute_lie_percentages(labels, receivers)\n",
        "    speaker_receiver_lie_percent = compute_lie_percentages(labels, speakers_receivers)\n",
        "    season_lie_percent = compute_lie_percentages(labels, seasons)\n",
        "    year_lie_percent = compute_lie_percentages(labels, years)\n",
        "\n",
        "    return {\n",
        "        \"Speaker Lie Percentage\": speaker_lie_percent,\n",
        "        \"Receiver Lie Percentage\": receiver_lie_percent,\n",
        "        \"Speaker-Receiver Pair Lie Percentage\": speaker_receiver_lie_percent,\n",
        "        \"Season Lie Percentage\": season_lie_percent,\n",
        "        \"Year Lie Percentage\": year_lie_percent,\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i4P5ADQxDBPS"
      },
      "outputs": [],
      "source": [
        "# Compute lie percentages\n",
        "lie_percentages_train = compute_lie_percentages_for_all(train_full)\n",
        "lie_percentages_valid = compute_lie_percentages_for_all(valid_full)\n",
        "\n",
        "# Display results\n",
        "import pandas as pd\n",
        "for key, value in lie_percentages_train.items():\n",
        "    if key == \"Speaker Lie Percentage\":\n",
        "        df = pd.DataFrame(value.items(), columns=[\"Speaker\", \"Lie Percentage (%)\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "OUNTmktlCDeC",
        "outputId": "be522a67-52eb-47be-e09d-1006f2e1d766"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 7,\n  \"fields\": [\n    {\n      \"column\": \"Speaker\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 7,\n        \"samples\": [\n          \"italy\",\n          \"germany\",\n          \"turkey\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Lie Percentage (%)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.7305435912765494,\n        \"min\": 2.1225470564677615,\n        \"max\": 8.547717842323651,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          8.547717842323651,\n          2.1225470564677615,\n          3.000882612533098\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-8197f9a8-f004-489e-be03-f21904dd3df5\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Speaker</th>\n",
              "      <th>Lie Percentage (%)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>italy</td>\n",
              "      <td>8.547718</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>germany</td>\n",
              "      <td>2.122547</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>austria</td>\n",
              "      <td>2.928071</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>russia</td>\n",
              "      <td>2.838221</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>england</td>\n",
              "      <td>3.313840</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>turkey</td>\n",
              "      <td>3.000883</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>france</td>\n",
              "      <td>8.221797</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8197f9a8-f004-489e-be03-f21904dd3df5')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-8197f9a8-f004-489e-be03-f21904dd3df5 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-8197f9a8-f004-489e-be03-f21904dd3df5');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-9db07873-caeb-48d8-b285-6738e987b882\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-9db07873-caeb-48d8-b285-6738e987b882')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-9db07873-caeb-48d8-b285-6738e987b882 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_efcf653b-167f-4832-a930-a980b161817f\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_efcf653b-167f-4832-a930-a980b161817f button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "   Speaker  Lie Percentage (%)\n",
              "0    italy            8.547718\n",
              "1  germany            2.122547\n",
              "2  austria            2.928071\n",
              "3   russia            2.838221\n",
              "4  england            3.313840\n",
              "5   turkey            3.000883\n",
              "6   france            8.221797"
            ]
          },
          "execution_count": 75,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HBkRCvNXG8Ls"
      },
      "source": [
        "### Item 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KBsv-6XHG9XQ",
        "outputId": "a546a373-6c02-4b27-8bb3-0e3d8e300225"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "First 20 Truth Messages:\n",
            "1. Germany!\n",
            "\n",
            "Just the person I want to speak with. I have a somewhat crazy idea that I’ve always wanted to try with I/G, but I’ve never actually convinced the other guy to try it. And, what’s worse, it might make you suspicious of me. \n",
            "\n",
            "So...do I suggest it?\n",
            "\n",
            "I’m thinking that this is a low stakes game, not a tournament or anything, and an interesting and unusual move set might make it more fun? That’s my hope anyway.\n",
            "\n",
            "What is your appetite like for unusual and crazy?\n",
            "2. You've whet my appetite, Italy. What's the suggestion?\n",
            "3. 👍\n",
            "4. It seems like there are a lot of ways that could go wrong...I don't see why France would see you approaching/taking Munich--while I do nothing about it--and not immediately feel skittish\n",
            "5. Yeah, I can’t say I’ve tried it and it works, cause I’ve never tried it or seen it. But how I think it would work is (a) my Spring move looks like an attack on Austria, so it would not be surprising if you did not cover Munich. Then (b) you build two armies, which looks like we’re really at war and you’re going to eject me. Then we launch the attack in Spring. So there is really no part of this that would raise alarm bells with France.\n",
            "\n",
            "All that said, I’ve literally never done it before, and it does involve risk for you, so I’m not offended or concerned if it’s just not for you. I’m happy to play more conventionally too. Up to you.\n",
            "6. I am just sensing that you don’t like this idea, so shall we talk about something else? That was just a crazy idea I’ve always wanted to try. I’m happy to play more conservatively.\n",
            "7. Any thoughts?\n",
            "8. Sorry Italy I've been away doing, um, German things. Brewing Lagers?\n",
            "9. I don't think I'm ready to go for that idea, however I'd be down for some good ol'-fashioned Austria-kicking?\n",
            "10. I am pretty conflicted about whether to guess that you were telling the truth or lying about the “brewing lagers” thing. I am going to take it literally and say 👎 even though I don’t think you meant it deceptively. 😉\n",
            "11. But I think I can get over “Lagergate” and we can still be friends. \n",
            "\n",
            "As of right now, I think Austria may be my most reliable ally. I’m thinking I’d like to play as a Central Trio if you have any interest in that. Thoughts?\n",
            "12. We haven't even passed a season yet and you have a 'most reliable ally'?\n",
            "\n",
            "I'll consider this proposal but, basically, I'm not going to expose myself to risk from either of you until I've seen a bit of your behavior\n",
            "13. Well, at least I have an idea of who to trust. Obviously, my ideas are subject to change. \n",
            "\n",
            "I understand your desire to watch behavior before committing to anything. I, personally, am a partner player. I look carefully early in the game for a small group to work with, and then I value loyalty and collaboration. I like to work closely with a tight-knit alliance. \n",
            "\n",
            "If you prefer to hop and back and forth, or play more of an individual game, then we might not be a good match. \n",
            "\n",
            "I’m looking for a loyal ally or two that I can coordinate with and make awesome moves with. Makes the game easier and a lot more fun.\n",
            "14. Just an FYI: I’ve now had both England and France suggest to me that I should move to Tyrolia and France will support me to Munich in the Fall. One saying that to me is not a big deal, but with both mentioning it, my alarm bells are going off. I am concerned about an E/F. \n",
            "\n",
            "I’m certainly not moving to Tyrolia. But I just want you to be cautious here. I feel like England and France are working together.\n",
            "15. I appreciate the tip, but I'm wondering why you're so against ousting me from Munich if I haven't explicitly agreed to be your ally?\n",
            "16. Because it is terrible, terrible play for Italy to attack Germany, in my view. If I were to attack you in Munich, I could never hold Munich. So, all I would be doing is weakening you, and helping France, England, or both to get really big. \n",
            "\n",
            "I don’t have any long-term path going north. Helping France to take you down is a sucker’s play, whether you are working with me or not.\n",
            "17. Did France tell you he was moving to Burgundy, or was that a stab?\n",
            "18. I was not informed of it, no. And England is leading me to believe it's part of a play for Belgium, so if they're working together this might be a trick...\n",
            "\n",
            "Italy, you seem like a straight shooter, and Austria has confirmed with me about your two's alliance. So I'll confide in you--this is my first ever game of diplomacy, and I think that teaming up with the two of you could help me learn more and have more fun. So, if you're still interested in a central powers alliance, I'm in.\n",
            "19. Okay full disclosure: I'm not very smart, and I accidentally let slip to England that you told me France was plotting to take Munich. I'm sorry for the error but I figured it was better to admit it so you know that England/France may not trust you.\n",
            "20. Okay, thanks for telling me.\n",
            "\n",
            "First 20 Lie Messages:\n",
            "1. I really don’t think that’s a fair description. You guys both wanted to attack each other. I encouraged you both to keep working together.\n",
            "2. We’re friends, right? I believe that every single message I’ve sent you all game has been truth, and I’ve gone out of my way to give you candid advice. Are we still friends?\n",
            "3. I have to say that I’m surprised that you feel that I’ve betrayed your trust. I have been feeling like maybe I’ve been TOO helpful to you, and been a bit over the top in offering advice, etc., but it seems like I’ve misread the situation.\n",
            "4. Here’s the deal: I like you better than England.\n",
            "5. But I don’t think there is anything wrong with me contemplating moves without telling you all of them. You asked me about it, and I told you the truth.\n",
            "6. Well, I have been honest with both you and France. You told me that I need to promise you a set of things in order to take the Channel. I felt like it was more than I could be sure of doing, so I am not entering the Channel. I won’t go there without your permission.\n",
            "7. Ha! Yeah, fat chance.\n",
            "8. Good!\n",
            "\n",
            "Still, I think we should show him some good faith by supporting him to Brest in Spring. We can decide in Fall whether it makes more sense for you to take it, but I think we want to keep France hungry.\n",
            "9. I would suggest something like this to ensure the English fleet is disbanded:\n",
            "Pic - Bre\n",
            "MAO - Channel\n",
            "Par S Pic - Bre\n",
            "10. I think that we should offer France Brest in Spring. That ensures that he is with us. Then, if conditions are right in the Fall, I can support you into Brest. But...England can offer France Belgium, and I think he is sure to take that if we’re not even offering him a center, right?\n",
            "11. Better to keep France feeling like we’re going to keep him in the game. If you need the build in Fall, it’s easy for me to support you there.\n",
            "12. Here is my take: If France just wanted to go down in a blaze of glory and say “eff you” to England, he would have kept Irish Sea. He kept Pic, which is next to his home center, and gives him a chance to negotiate with both you and England.\n",
            "13. I’m pretty wary of England right now. He asked me what I want to do, but I feel like he’s trying to get me to leave MAO open. That’s not terrible news, as it suggests that he won’t expect your move to North Sea.\n",
            "14. Ahhhh, sneaky Devil! Thank you for letting me know.\n",
            "15. I still like our plan.\n",
            "16. I need to run for a bit. I’ll be around in a few hours.\n",
            "17. Okay. Should I support Pic to Bre?\n",
            "18. Consider it done.\n",
            "19. I’d love to talk if you’re there. I’m getting the impression that England may actually be moving on you, and I think I have a good counter, but I also still think we should support the attack on Brest and take North Sea.\n",
            "20. Nice! Get’em! He WAS moving on you. But we should be able to take about 3 off of him now. Very nice turn.\n"
          ]
        }
      ],
      "source": [
        "# Extract messages and labels from training data\n",
        "messages, labels = train\n",
        "\n",
        "# Store first 20 truth messages (label = 1) and first 20 lies (label = 0)\n",
        "truth_messages = []\n",
        "lie_messages = []\n",
        "\n",
        "# Iterate through training data and collect messages\n",
        "for msg, label in zip(messages, labels):\n",
        "    if label == 1 and len(truth_messages) < 20:\n",
        "        truth_messages.append(msg)\n",
        "    elif label == 0 and len(lie_messages) < 20:\n",
        "        lie_messages.append(msg)\n",
        "    # Stop when we have 20 of each\n",
        "    if len(truth_messages) == 20 and len(lie_messages) == 20:\n",
        "        break\n",
        "\n",
        "# Print results\n",
        "print(\"First 20 Truth Messages:\")\n",
        "for i, msg in enumerate(truth_messages, 1):\n",
        "    print(f\"{i}. {msg}\")\n",
        "\n",
        "print(\"\\nFirst 20 Lie Messages:\")\n",
        "for i, msg in enumerate(lie_messages, 1):\n",
        "    print(f\"{i}. {msg}\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
